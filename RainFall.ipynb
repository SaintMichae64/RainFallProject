{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6744981-009a-455a-bd57-55e7c06a4784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:977: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:964: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Cycle #1: mean_squared_error 1219.2734591289632\n",
      "Cycle #2: mean_squared_error 495.8826637638425\n",
      "Cycle #3: mean_squared_error 213.60092548259254\n",
      "Cycle #4: mean_squared_error 153.29639723694441\n",
      "Cycle #5: mean_squared_error 119.7521164533004\n",
      "Cycle #6: mean_squared_error 146.6669905579206\n",
      "Cycle #7: mean_squared_error 117.64078188405453\n",
      "Cycle #8: mean_squared_error 106.11458224694705\n",
      "Cycle #9: mean_squared_error 110.94165261277875\n",
      "Cycle #10: mean_squared_error 114.67318829286445\n",
      "Cycle #11: mean_squared_error 102.10873079762875\n",
      "Cycle #12: mean_squared_error 108.49479379005803\n",
      "Cycle #13: mean_squared_error 106.07413586366523\n",
      "Cycle #14: mean_squared_error 107.25799738319175\n",
      "Cycle #15: mean_squared_error 119.62861559228989\n",
      "Cycle #16: mean_squared_error 111.00914231087397\n",
      "Cycle #17: mean_squared_error 106.46973589554574\n",
      "Cycle #18: mean_squared_error 104.36729394116448\n",
      "Cycle #19: mean_squared_error 91.84754269794352\n",
      "Cycle #20: mean_squared_error 116.98009150236555\n",
      "Cycle #21: mean_squared_error 104.32743316946677\n",
      "Cycle #22: mean_squared_error 111.18016392976335\n",
      "Cycle #23: mean_squared_error 118.02206998658411\n",
      "Cycle #24: mean_squared_error 109.26463734524921\n",
      "Cycle #25: mean_squared_error 115.64435747757699\n",
      "Cycle #26: mean_squared_error 125.12667802236612\n",
      "Cycle #27: mean_squared_error 86.74417877197266\n",
      "Cycle #28: mean_squared_error 113.6821464612646\n",
      "Cycle #29: mean_squared_error 112.47461278230242\n",
      "Cycle #30: mean_squared_error 112.94125247696071\n",
      "Cycle #31: mean_squared_error 103.3060662723282\n",
      "Cycle #32: mean_squared_error 119.44729332785005\n"
     ]
    }
   ],
   "source": [
    "# import subprocess\n",
    "# import sys\n",
    "\n",
    "# def install(package):\n",
    "#    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install packages\n",
    "# install('tensorflow')\n",
    "# install('keras')\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "#import sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "concrete_data.head(10)\n",
    "\n",
    "concrete_data.shape\n",
    "\n",
    "concrete_data.describe()\n",
    "\n",
    "concrete_data.isnull().sum()\n",
    "\n",
    "concrete_data_columns = concrete_data.columns\n",
    "\n",
    "target = concrete_data['Strength']\n",
    "target.head(10)\n",
    "\n",
    "predictors = concrete_data.iloc[:, :-1]\n",
    "predictors.head(10)\n",
    "\n",
    "#num of inputs = num of predictors colums\n",
    "n_cols = predictors.shape[1]\n",
    "def regression_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "model = regression_model()\n",
    "\n",
    "list_of_mean_squared_error = []\n",
    "for cycle in range(50):\n",
    "    #Randomly split the data into a training set (80%) and a test set (20%):  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.2)\n",
    "    #Train and test the model at the same time\n",
    "    res = model.fit(X_train, y_train, epochs=50, verbose=0, validation_data=(X_test, y_test))\n",
    "    #Find mean_squared_error as last value in history.\n",
    "    mean_squared_error = res.history['val_loss'][-1]\n",
    "    #Add value of mean_squared_error for every cycle in list.\n",
    "    list_of_mean_squared_error.append(mean_squared_error)\n",
    "    print('Cycle #{}: mean_squared_error {}'.format(cycle+1, mean_squared_error))\n",
    "\n",
    "print('The mean of the mean squared errors: {}'.format(np.mean(list_of_mean_squared_error)))\n",
    "print('The standard deviation of the mean squared errors: {}'.format(np.std(list_of_mean_squared_error)))\n",
    "\n",
    "predictors_norm = (predictors - predictors.mean())/predictors.std()\n",
    "predictors_norm.head(10)\n",
    "\n",
    "n_cols = predictors_norm.shape[1]\n",
    "def regression_model2():\n",
    "    model2 = Sequential()\n",
    "    model2.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model2.add(Dense(1))\n",
    "    \n",
    "    model2.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model2\n",
    "\n",
    "model2 = regression_model2()\n",
    "\n",
    "list_of_mean_squared_error = []\n",
    "for cycle in range(50):\n",
    "    #Randomly split the data into a training set (80%) and a test set (20%):  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.2)\n",
    "    #Train and test the model at the same time\n",
    "    res = model2.fit(X_train, y_train, epochs=50, verbose=0, validation_data=(X_test, y_test))\n",
    "    #Find mean_squared_error as last value in history.\n",
    "    mean_squared_error = res.history['val_loss'][-1]\n",
    "    #Add value of mean_squared_error for every cycle in list.\n",
    "    list_of_mean_squared_error.append(mean_squared_error)\n",
    "    print('Cycle #{}: mean_squared_error {}'.format(cycle+1, mean_squared_error))\n",
    "\n",
    "print('The mean of the mean squared errors: {}'.format(np.mean(list_of_mean_squared_error)))\n",
    "print('The standard deviation of the mean squared errors: {}'.format(np.std(list_of_mean_squared_error)))\n",
    "\n",
    "def regression_model3():\n",
    "    model3 = Sequential()\n",
    "    model3.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model3.add(Dense(1))\n",
    "    \n",
    "    model3.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model3\n",
    "\n",
    "model3 = regression_model3() \n",
    "\n",
    "list_of_mean_squared_error = []\n",
    "for cycle in range(50):\n",
    "    #Randomly split the data into a training set (80%) and a test set (20%):  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.2)\n",
    "    #Train and test the model at the same time\n",
    "    res = model3.fit(X_train, y_train, epochs=100, verbose=0, validation_data=(X_test, y_test))\n",
    "    #Find mean_squared_error as last value in history.\n",
    "    mean_squared_error = res.history['val_loss'][-1]\n",
    "    #Add value of mean_squared_error for every cycle in list.\n",
    "    list_of_mean_squared_error.append(mean_squared_error)\n",
    "    print('Cycle #{}: mean_squared_error {}'.format(cycle+1, mean_squared_error))\n",
    "\n",
    "print('The mean of the mean squared errors: {}'.format(np.mean(list_of_mean_squared_error)))\n",
    "print('The standard deviation of the mean squared errors: {}'.format(np.std(list_of_mean_squared_error)))\n",
    "\n",
    "def regression_model4():\n",
    "    model4 = Sequential()\n",
    "    model4.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model4.add(Dense(10, activation='relu'))\n",
    "    model4.add(Dense(10, activation='relu'))\n",
    "    model4.add(Dense(1))\n",
    "    \n",
    "    model4.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model4\n",
    "\n",
    "model4 = regression_model4()\n",
    "\n",
    "list_of_mean_squared_error = []\n",
    "for cycle in range(50):\n",
    "    #Randomly split the data into a training set (80%) and a test set (20%):  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.2)\n",
    "    #Train and test the model at the same time\n",
    "    res = model4.fit(X_train, y_train, epochs=50, verbose=0, validation_data=(X_test, y_test))\n",
    "    #Find mean_squared_error as last value in history.\n",
    "    mean_squared_error = res.history['val_loss'][-1]\n",
    "    #Add value of mean_squared_error for every cycle in list.\n",
    "    list_of_mean_squared_error.append(mean_squared_error)\n",
    "    print('Cycle #{}: mean_squared_error {}'.format(cycle+1, mean_squared_error))\n",
    "\n",
    "print('The mean of the mean squared errors: {}'.format(np.mean(list_of_mean_squared_error)))\n",
    "print('The standard deviation of the mean squared errors: {}'.format(np.std(list_of_mean_squared_error)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1b2f8a-702d-4e25-b98e-4a373e66bd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
